{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "inference.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40f9VBOnRWJj",
        "colab_type": "text"
      },
      "source": [
        "# YOLO in TensorFlow: Inference Tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LarZmCip39it",
        "colab_type": "text"
      },
      "source": [
        "This is a Google Colaboratory notebook file to demonstrate inference using the TensorFlow Model Garden implementation of YOLOv3 on a video stream from your webcam.\n",
        "\n",
        "First, clone the GitHub repo and import the necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rECnP_DMQnZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "from google.colab import output\n",
        "from IPython.display import JSON\n",
        "\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "import pathlib\n",
        "import urllib.request\n",
        "\n",
        "# Clone the tensorflow models repository if it doesn't already exist\n",
        "if \"TensorFlowModelGardeners\" in pathlib.Path.cwd().parts:\n",
        "  while \"TensorFlowModelGardeners\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir('..')\n",
        "elif not pathlib.Path('TensorFlowModelGardeners').exists():\n",
        "  !git clone --depth 1 --branch v3-new-api https://github.com/PurdueCAM2Project/TensorFlowModelGardeners\n",
        "os.chdir('TensorFlowModelGardeners')\n",
        "!git pull\n",
        "\n",
        "from yolo import Yolov3\n",
        "from yolo.utils.testing_utils import int_scale_boxes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rwMRMTs5Fiq",
        "colab_type": "text"
      },
      "source": [
        "After cloning the repo, build the model and load the Darknet (paper implementation) pretrained weights. This may take time since Colab needs to download the weights.\n",
        "\n",
        "A prediction function for the model is also created. The [`predict`](https://www.tensorflow.org/api_docs/python/tf/keras/Model?hl=en#predict) function is faster for batched inputs (many images being processed at the same time) than it is for single images, like used in this tutorial. It is used for the sake of example here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLqIfPcI5HEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Yolov3(type=\"regular\", classes=80)\n",
        "model.load_weights_from_dn(dn2tf_backbone = True, dn2tf_head = True)\n",
        "model.set_prediction_filter()\n",
        "model.make_predict_function()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWL8QjTb5HoN",
        "colab_type": "text"
      },
      "source": [
        "Below is a function to infer the bounding boxes from an online image using the YOLO model. The frontend will pass the image from the webcam to the backend function in Colab by using a URI. When the backend function receives the image, it will decode the image into a Numpy array of integers (0 to 255) with 3 dimensions (width, height, RGB channels). Next, it will use the TensorFlow to normalize the pixels and resize the image. After that, it will use the model to predict the bounding boxes for any objects that may appear in the image. Finally, the bounding box format is converted to a JSON object so it can be returned and shown on the frontend."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfXCscqgxqHP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A OpenCV flag to treat the input image as an RGB image. This flag has a\n",
        "# different name in OpenCV 2 and OpenCV 3, so a condition is needed to work with\n",
        "# both versions.\n",
        "COLOR_IMAGE = cv2.IMREAD_COLOR if int(cv2.__version__.split('.', 1)[0]) >= 3 \\\n",
        "  else cv2.CV_LOAD_IMAGE_COLOR\n",
        "\n",
        "def yolo_infer(uri: str) -> JSON:\n",
        "  # Decode the image\n",
        "  with urllib.request.urlopen(uri) as response:\n",
        "    data = response.read()\n",
        "  img_buf = np.frombuffer(data, np.uint8)\n",
        "  img = cv2.imdecode(img_buf, COLOR_IMAGE)\n",
        "  \n",
        "  # Preprocess the image\n",
        "  mat = tf.cast(img, tf.float16)\n",
        "  mat /= 255\n",
        "  mat = tf.expand_dims(mat, axis = 0)\n",
        "  mat = tf.image.resize(mat, model.input_image_size)\n",
        "\n",
        "  # Run the inference\n",
        "  pred = model.predict(mat)\n",
        "\n",
        "  # Rescale bounding boxes\n",
        "  out, classes = int_scale_boxes(pred[0], pred[1], 500, 375)\n",
        "\n",
        "  # Convert the format of the bounding boxes to match the format in the\n",
        "  # HTML document shown below: [x1, x2, y1, y2, c, p]\n",
        "  out = out[0].numpy()\n",
        "  classes = classes[0].numpy()\n",
        "  boxes = []\n",
        "  for i in range(out.shape[0]):\n",
        "    if out[i][3] == 0:\n",
        "      break\n",
        "    boxes.append(list(out[i]) + [classes[i], pred[2][0][i]])\n",
        "\n",
        "  # Return control to the client side (JavaScript in the HTML document)\n",
        "  return JSON(boxes)\n",
        "\n",
        "output.register_callback('yolo_infer', yolo_infer)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izo0wxEMMX42",
        "colab_type": "text"
      },
      "source": [
        "Below is a frontend interface to access the webcam, and stream the images to the backend, and display the bounding boxes to the user. The stream uses JPEG compression to speed up the transfer of images to Colab. The `yolo_infer` function that was made earlier is then called on the compressed JPEG image and the resulting bounding boxes are then drawn on the webcam images when they are recieved back from the backend."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWcPgacBSlvm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%html\n",
        "<!--\n",
        "  Sources:\n",
        "    https://www.kirupa.com/html5/accessing_your_webcam_in_html5.htm\n",
        "    https://developer.mozilla.org/en-US/docs/Web/Guide/Audio_and_video_manipulation -->\n",
        "\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "<meta charset=\"utf-8\">\n",
        "<style>\n",
        "#container {\n",
        "\tmargin: 0px auto;\n",
        "\twidth: 500px;\n",
        "\theight: 375px;\n",
        "\tborder: 10px #333 solid;\n",
        "}\n",
        "#videoElement {\n",
        "\twidth: 500px;\n",
        "\theight: 375px;\n",
        "\tbackground-color: #666;\n",
        "}\n",
        "#my-canvas {\n",
        "\tbackground-color: #666;\n",
        "}\n",
        "</style>\n",
        "</head>\n",
        " \n",
        "<body>\n",
        "<div id=\"container\">\n",
        "  <canvas id=\"my-canvas\" width=\"500\" height=\"375\"></canvas>\n",
        "\t<video autoplay=\"true\" id=\"videoElement\" style=\"visibility:hidden\"></video>\n",
        "</div>\n",
        "\n",
        "<button id=\"toggleWebcam\">Start Webcam</button>\n",
        "\n",
        "<script src=\"https://code.jquery.com/jquery-3.5.1.min.js\" integrity=\"sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=\" crossorigin=\"anonymous\"></script>\n",
        "<script>\n",
        "  // Load COCO class names from the repo and give the classes seemingly random, but distinct, colors\n",
        "  var classes;\n",
        "  var colors = [];\n",
        "  $.ajax({\n",
        "    url: 'https://raw.githubusercontent.com/PurdueCAM2Project/TensorFlowModelGardeners/master/yolo/dataloaders/dataset_specs/coco.names',\n",
        "    success: function(data) {\n",
        "      classes = data.split('\\n');\n",
        "      for (var i = 0; i < classes.length; i++) {\n",
        "        colors.push(\"#\" + Math.round(0x1000000 * (i / classes.length)).toString(16));\n",
        "      }\n",
        "      for (var i = colors.length - 1; i >= 0; i--) {\n",
        "          j = Math.floor(Math.random() * (i + 1));\n",
        "          x = colors[i];\n",
        "          colors[i] = colors[j];\n",
        "          colors[j] = x;\n",
        "      }\n",
        "    }\n",
        "  });\n",
        "\n",
        "  var video = document.querySelector(\"#videoElement\");\n",
        "  var toggleWebcamButton = document.querySelector(\"#toggleWebcam\");\n",
        "  var camOn = false;\n",
        "\n",
        "  function startWebcam(e) {\n",
        "    camOn = true;\n",
        "    if (navigator.mediaDevices.getUserMedia) {\n",
        "      navigator.mediaDevices.getUserMedia({ video: true })\n",
        "        .then(function (stream) {\n",
        "          video.srcObject = stream;\n",
        "        })\n",
        "        .catch(function (err0r) {\n",
        "          console.log(\"Something went wrong!\");\n",
        "        });\n",
        "    }\n",
        "  }\n",
        "\n",
        "  function stopWebcam(e) {\n",
        "    var stream = video.srcObject;\n",
        "    var tracks = stream.getTracks();\n",
        "\n",
        "    for (var i = 0; i < tracks.length; i++) {\n",
        "      var track = tracks[i];\n",
        "      track.stop();\n",
        "    }\n",
        "\n",
        "    video.srcObject = null;\n",
        "    camOn = false;\n",
        "  }\n",
        "\n",
        "  function toggleWebcam(e) {\n",
        "    if (camOn) {\n",
        "      stopWebcam(e);\n",
        "      toggleWebcamButton.innerText = \"Start Webcam\";\n",
        "    } else {\n",
        "      startWebcam(e);\n",
        "      toggleWebcamButton.innerText = \"Stop Webcam\";\n",
        "      processor.doLoad();\n",
        "    }\n",
        "  }\n",
        "\n",
        "  toggleWebcamButton.addEventListener(\"click\", toggleWebcam);\n",
        "\n",
        "  var processor = {  \n",
        "    timerCallback: async function() {  \n",
        "      if (!camOn) {  \n",
        "        return;  \n",
        "      }  \n",
        "      await this.computeFrame();  \n",
        "      var self = this;  \n",
        "      setTimeout(function () {  \n",
        "        self.timerCallback();  \n",
        "      }, 0);\n",
        "    },\n",
        "\n",
        "    doLoad: function() {\n",
        "      this.video = document.getElementById(\"videoElement\");\n",
        "      this.c1 = document.getElementById(\"my-canvas\");\n",
        "      this.ctx1 = this.c1.getContext(\"2d\");\n",
        "      this.lastFrameBoundingBoxes = [];\n",
        "\n",
        "      this.width = 500;  \n",
        "      this.height = 375;  \n",
        "      this.timerCallback();\n",
        "    },  \n",
        "\n",
        "    computeFrame: async function() {\n",
        "      this.ctx1.drawImage(this.video, 0, 0, this.width, this.height);\n",
        "      var frame = this.ctx1.getImageData(0, 0, this.width, this.height);\n",
        "\n",
        "      this.ctx1.putImageData(frame, 0, 0);\n",
        "      var url = this.c1.toDataURL('image/jpeg', 0.8);\n",
        "      this.drawBoundingBoxes(this.lastFrameBoundingBoxes);\n",
        "      var result = await google.colab.kernel.invokeFunction('yolo_infer', [url], {});\n",
        "      this.lastFrameBoundingBoxes = result.data['application/json'];\n",
        "      return;\n",
        "    },\n",
        "\n",
        "    drawBoundingBoxes: function(boxes) {\n",
        "      for (var i = 0; i < boxes.length; i++) {\n",
        "        const [x1, x2, y1, y2, c, p] = boxes[i];\n",
        "        console.log([classes[c] + \", \" + p, x1, y1]);\n",
        "        debugger;\n",
        "        this.ctx1.beginPath();\n",
        "        this.ctx1.lineWidth = \"2\";\n",
        "        this.ctx1.strokeStyle = colors[c];\n",
        "        this.ctx1.rect(x1, y1, x2-x1, y2-y1);\n",
        "        this.ctx1.stroke();\n",
        "        this.ctx1.font = \"18px Monospace\";\n",
        "        this.ctx1.fillStyle = colors[c];\n",
        "        this.ctx1.fillText(classes[c] + \", \" + p.toFixed(2), x1, y1 - 3);\n",
        "      }\n",
        "    }\n",
        "  };\n",
        "</script>\n",
        "</body>\n",
        "</html>"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}