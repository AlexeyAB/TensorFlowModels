{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FINAL_DATAPIPELINE.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFGgVsNcZJRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow_probability as tfp\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, array_to_img\n",
        "from random import randrange\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.ndimage as ndimage\n",
        "import numpy as np\n",
        "from numpy import expand_dims\n",
        "\n",
        "def zoom(img, zoom_factor):\n",
        "  img = img.numpy()\n",
        "  zoom_factor = zoom_factor.numpy()\n",
        "  h, w = img.shape[:2]\n",
        "  zoom_tuple = (zoom_factor,) * 2 + (1,) * (img.ndim - 2)\n",
        "  # Zooming out\n",
        "  if zoom_factor < 1:\n",
        "    zh = int(np.round(h * zoom_factor))\n",
        "    zw = int(np.round(w * zoom_factor))\n",
        "    top = (h - zh) // 2\n",
        "    left = (w - zw) // 2\n",
        "    # Zero-padding\n",
        "    out = np.zeros_like(img)\n",
        "    out[top:top+zh, left:left+zw] = ndimage.zoom(img, zoom_tuple)\n",
        "  # Zooming in\n",
        "  elif zoom_factor > 1:\n",
        "    zh = int(np.round(h / zoom_factor))\n",
        "    zw = int(np.round(w / zoom_factor))\n",
        "    top = (h - zh) // 2\n",
        "    left = (w - zw) // 2\n",
        "    out = ndimage.zoom(img[top:top+zh, left:left+zw], zoom_tuple)\n",
        "  # No Zoom\n",
        "  else:\n",
        "    out = img\n",
        "  return out\n",
        "\n",
        "def rotate(img, angle):\n",
        "  img = img.numpy()\n",
        "  angle = angle.numpy()\n",
        "  rotated_img = ndimage.rotate(img, angle, reshape=False)\n",
        "  return rotated_img\n",
        "\n",
        "def rand_scale(s):\n",
        "  scale = np.random.uniform(low = 1, high = s)\n",
        "  if (np.random.randint(low = 0, high = 9223372036854775807)%2):\n",
        "      return scale\n",
        "  return  1/scale\n",
        "\n",
        "\n",
        "def preprocessing_selection(choice):\n",
        "  def train_preprocess_image_classification(image, label):\n",
        "    low = 128\n",
        "    high = 448\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    deg = np.random.uniform(low = -7, high = 7)\n",
        "    aspect = rand_scale(0.75)\n",
        "    width = image.shape[1]\n",
        "    height = image.shape[0]\n",
        "    scale = int(np.random.randint(low = low, high = high))/224\n",
        "    image = tf.image.resize(image, (width, int(width/aspect)), preserve_aspect_ratio=False)\n",
        "    shape = [image.shape[0], image.shape[1], image.shape[2]]\n",
        "    image = tf.py_function(zoom, [image, scale], tf.float32)\n",
        "    try:\n",
        "      image.set_shape(shape)\n",
        "    except:\n",
        "      pass\n",
        "    image = tf.py_function(rotate, [image, deg], tf.float32)\n",
        "    try:\n",
        "      image.set_shape(shape)\n",
        "    except:\n",
        "      pass\n",
        "    image = tf.image.resize_with_pad(image, target_width=224, target_height=224)\n",
        "    if image.shape[-1] > 1:\n",
        "      image = tf.image.adjust_hue(image, np.random.uniform(low = -0.1, high = 0.1))\n",
        "      image = tf.image.adjust_saturation(image, rand_scale(.75))\n",
        "    image = tf.image.adjust_brightness(image, rand_scale(.75))\n",
        "    image = image / 255\n",
        "    return image, label\n",
        "\n",
        "  def train_preprocess_priming_classification(image, label):\n",
        "    low = 448\n",
        "    high = 512\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    width = image.shape[1]\n",
        "    height = image.shape[0]\n",
        "    scale = int(np.random.randint(low = low, high = high))/448\n",
        "    shape = [image.shape[0], image.shape[1], image.shape[2]]\n",
        "    image = tf.py_function(zoom, [image, scale], tf.float32)\n",
        "    image.set_shape(shape)\n",
        "    image = tf.image.resize_with_pad(image, target_width=448, target_height=448)\n",
        "    image = image / 255\n",
        "    return image, label\n",
        "\n",
        "  def train_preprocess_object_detection(image, label):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    width = image.shape[1]\n",
        "    height = image.shape[0]\n",
        "    resize_num = np.random.randint(low = 10, high = 19)*32\n",
        "    image = tf.image.resize_with_pad(image, target_width=resize_num, target_height=resize_num)\n",
        "    image = tf.image.adjust_hue(image, np.random.uniform(low = -0.1, high = 0.1))\n",
        "    image = tf.image.adjust_saturation(image, rand_scale(1.5))\n",
        "    image = tf.image.adjust_brightness(image, rand_scale(1.5))\n",
        "    image = image / 255\n",
        "    return image, label\n",
        "\n",
        "  try:\n",
        "    if choice.lower() == \"detection\":\n",
        "      return train_preprocess_object_detection\n",
        "    elif choice.lower() == \"classification\":\n",
        "      return train_preprocess_image_classification\n",
        "    elif choice.lower() == \"priming\":\n",
        "      return train_preprocess_priming_classification\n",
        "    else:\n",
        "      NameError('Invalid Input')\n",
        "  except:\n",
        "    raise NameError('Invalid Input')\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCrf1d00j8ZR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#param train, top%, bottom%, type Splits before \n",
        "def preprocessing(training_dataset, data_augmentation_split, type_of_preprocessing, size_of_dataset):\n",
        "  non_preprocessed_split = int(((100 - data_augmentation_split)/100)*size_of_dataset)\n",
        "  data_augmentation_split = int((data_augmentation_split/100)*size_of_dataset)\n",
        "\n",
        "  data_augmentation_dataset = training_dataset.take(data_augmentation_split)\n",
        "  remaining = training_dataset.skip(data_augmentation_split)  \n",
        "  non_preprocessed_split = remaining.take(non_preprocessed_split)\n",
        "\n",
        "  '''\n",
        "  Try to split dataset without having to use tfds.load \n",
        "  but rather split the training_dataset object itself.\n",
        "\n",
        "  ***UPDATE***\n",
        "  Got size of Dataset via:\n",
        "  Dataset, Info = tfds.load('mnist', split=['train', 'test'], with_info=True)\n",
        "  Train = Dataset[0]\n",
        "  Test = Dataset[1]\n",
        "  Size = int(Info.splits['train'].num_examples)\n",
        "  \n",
        "  --------------------------------------------------------------------------------\n",
        "\n",
        "  And Split via:\n",
        "  non_preprocessed_split = int(((100 - data_augmentation_split)/100)*size_of_dataset)\n",
        "  data_augmentation_split = int((data_augmentation_split/100)*size_of_dataset)\n",
        "  data_augmentation_dataset = training_dataset.take(data_augmentation_split)\n",
        "  remaining = training_dataset.skip(data_augmentation_split)  \n",
        "  non_preprocessed_split = remaining.take(non_preprocessed_split)\n",
        "\n",
        "\n",
        "  was able to split the datset\n",
        "\n",
        "  ###############################################################\n",
        "  REASONS WHY MAP FUNCTION IS NOT WORKING:\n",
        "  1. make sure as_supervised is true\n",
        "  2. rotate and zoom functions are not working properly, they only work with numpy arrays\n",
        "  3. concatenation is not working, different types due to casting (probably need to normalize the non_preprocessed part too) (fixed)\n",
        "  ################################################################\n",
        "  I already commented out the lines that are not working\n",
        "  update: concatenation works after adding the below normalize function\n",
        "  update: apparently tf.keras.preprocessing.image.random_rotate does not work with tensors\n",
        "  update: I can't figure out how to covert a tensor to a numpy array, .numpy() is not working\n",
        "  update: tfa.image.rotate works\n",
        "  '''\n",
        "  \n",
        "\n",
        "  def normalize(image, label):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = image / 255\n",
        "    return image, label\n",
        "\n",
        "\n",
        "  preprocessing_function = preprocessing_selection(\"classification\")\n",
        "  data_augmentation_dataset = data_augmentation_dataset.map(preprocessing_function, num_parallel_calls=4)\n",
        "  non_preprocessed_split = non_preprocessed_split.map(normalize, num_parallel_calls = 4)\n",
        "  data_augmentation_dataset.concatenate(non_preprocessed_split)\n",
        "  return data_augmentation_dataset\n",
        "\n",
        "Dataset, Info = tfds.load('mnist', split=['train', 'test'], with_info=True, as_supervised= True)\n",
        "Train = Dataset[0]\n",
        "Test = Dataset[1]\n",
        "Size = int(Info.splits['train'].num_examples)\n",
        "train_ds = preprocessing(Train, 5,\"classification\", Size)\n",
        "train_ds_sample = train_ds.take(1)\n",
        "\n",
        "\n",
        "for x,y in train_ds_sample:\n",
        "  x = tf.reshape(x, [x.shape[0], x.shape[1]])\n",
        "  plt.imshow(x)\n",
        "  break\n",
        "  image = img_to_array(x)\n",
        "\n",
        "#train_ds = train_ds.batch(batch_size)\n",
        "#train_ds = train_ds.prefetch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0XObrZ6j_US",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#testing\n",
        "image_string = tf.io.read_file('robertducky5.jpg')\n",
        "image_decoded = tf.image.decode_jpeg(image_string, channels=3)\n",
        "image = tf.cast(image_decoded, tf.float32)\n",
        "print(image.shape)\n",
        "label = 'A'\n",
        "preprocessing_function = preprocessing_selection(\"classification\")\n",
        "img, lb = preprocessing_function(image, label)\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGOUS40lkBkf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "dataset = dataset.map(train_preprocess, num_parallel_calls=4)\n",
        "dataset = dataset.batch(batch_size)\n",
        "dataset = dataset.prefetch(1)\n",
        "'''\n",
        "'''\n",
        "def train_preprocess(image, label):\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "\n",
        "    image = tf.image.random_brightness(image, max_delta=32.0 / 255.0)\n",
        "    image = tf.image.random_saturation(image, lower=0.5, upper=1.5)\n",
        "\n",
        "    #Make sure the image is still in [0, 1]\n",
        "    image = tf.clip_by_value(image, 0.0, 1.0)\n",
        "\n",
        "    return image, label\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}